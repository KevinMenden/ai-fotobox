{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cutting-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import utils\n",
    "from vgg import Vgg16\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.onnx\n",
    "\n",
    "from MobileStyleNet import MobileStyleNet\n",
    "from transformer_net import TransformerNet\n",
    "import torch.autograd.profiler as profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-mailman",
   "metadata": {},
   "source": [
    "# Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unauthorized-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_name = \"model_mobile_5e\"\n",
    "content_image = utils.load_image(\"/home/kevin/Pictures/neuseeland.jpg\", scale=2)\n",
    "\n",
    "content_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 1024)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.mul(255))\n",
    "])\n",
    "content_image = content_transform(content_image).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model = MobileStyleNet()\n",
    "    state_dict = torch.load(model_name)\n",
    "    # remove saved deprecated running_* keys in InstanceNorm from the checkpoint\n",
    "    for k in list(state_dict.keys()):\n",
    "        if re.search(r'in\\d+\\.running_(mean|var)$', k):\n",
    "            del state_dict[k]\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    output = model(content_image).cpu()\n",
    "    \n",
    "utils.save_image(\"test4.jpg\", output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-drain",
   "metadata": {},
   "source": [
    "# Performance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sunrise-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = TransformerNet().to(device)\n",
    "img = torch.rand((1, 3, 256, 256)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inclusive-piano",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 ms ± 24.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-russia",
   "metadata": {},
   "source": [
    "### Mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naval-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = MobileStyleNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seventh-gospel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 ms ± 4.73 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "mobilenet(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confident-zealand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference         1.62%       3.244ms        99.98%     200.688ms     200.688ms             1  \n",
      "                    aten::conv2d         0.05%     101.101us        63.96%     128.381ms       8.024ms            16  \n",
      "               aten::convolution         0.05%     108.442us        63.91%     128.279ms       8.017ms            16  \n",
      "              aten::_convolution         0.14%     290.809us        63.85%     128.171ms       8.011ms            16  \n",
      "        aten::mkldnn_convolution        63.61%     127.685ms        63.70%     127.855ms       7.991ms            16  \n",
      "          aten::reflection_pad2d        21.61%      43.373ms        21.67%      43.500ms       2.719ms            16  \n",
      "             aten::instance_norm         0.19%     378.520us         8.04%      16.131ms       1.075ms            15  \n",
      "                aten::batch_norm         0.03%      58.932us         7.11%      14.262ms     950.775us            15  \n",
      "    aten::_batch_norm_impl_index         0.05%      97.402us         7.08%      14.203ms     946.846us            15  \n",
      "         aten::native_batch_norm         5.56%      11.161ms         7.01%      14.062ms     937.463us            15  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 200.725ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profiler.profile(record_shapes=True) as prof:\n",
    "    with profiler.record_function(\"model_inference\"):\n",
    "        model(img)\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parliamentary-minute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                            Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                 model_inference         1.68%       2.628ms        99.98%     156.315ms     156.315ms             1  \n",
      "                    aten::conv2d         0.05%      84.772us        56.31%      88.044ms       5.870ms            15  \n",
      "               aten::convolution         0.06%      87.785us        56.26%      87.959ms       5.864ms            15  \n",
      "              aten::_convolution         0.15%     233.064us        56.20%      87.871ms       5.858ms            15  \n",
      "        aten::mkldnn_convolution        55.95%      87.471ms        56.04%      87.619ms       5.841ms            15  \n",
      "          aten::reflection_pad2d        14.87%      23.250ms        14.89%      23.286ms       7.762ms             3  \n",
      "        aten::upsample_nearest2d        13.44%      21.013ms        13.44%      21.018ms      21.018ms             1  \n",
      "             aten::instance_norm         0.15%     230.908us        10.11%      15.806ms       1.129ms            14  \n",
      "                aten::batch_norm         0.04%      63.621us         9.04%      14.130ms       1.009ms            14  \n",
      "    aten::_batch_norm_impl_index         0.05%      85.893us         9.00%      14.066ms       1.005ms            14  \n",
      "--------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 156.350ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profiler.profile(record_shapes=True) as prof:\n",
    "    with profiler.record_function(\"model_inference\"):\n",
    "        mobilenet(img)\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-sapphire",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:food-recognition] *",
   "language": "python",
   "name": "conda-env-food-recognition-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
